from __future__ import annotations

from collections.abc import Mapping, Sequence
from collections.abc import Set as AbcSet
from copy import deepcopy

import pytest
from hypothesis import given
from hypothesis import strategies as st

from etlutil import move_unknown_keys_to_extra, prune_data, walk
from etlutil.data_structures import convert_dict_types

# Property-based tests (skipped if hypothesis is not installed)
hypothesis = pytest.importorskip("hypothesis")


# Keys allowed in mappings (must be hashable)
hashable_key = st.one_of(
    st.text(),
    st.integers(),
    st.tuples(st.integers(), st.integers()),
)

# Elements allowed in sets/frozensets (must be hashable)
hashable_elem = st.one_of(
    st.text(),
    st.integers(),
    st.booleans(),
    st.tuples(st.integers(), st.integers()),
)


def recursive_data_strategy() -> st.SearchStrategy:
    """Generate nested structures: scalars, lists/tuples, dicts, sets/frozensets."""
    base = st.one_of(st.none(), st.booleans(), st.integers(), st.text())

    def expand(children: st.SearchStrategy) -> st.SearchStrategy:
        # Build containers from already-built children
        lists = st.lists(children, max_size=3)
        tuples = st.lists(children, max_size=3).map(tuple)
        mappings = st.dictionaries(keys=hashable_key, values=children, max_size=3)
        sets = st.sets(elements=hashable_elem, max_size=3)
        frozensets = st.sets(elements=hashable_elem, max_size=3).map(frozenset)
        return st.one_of(lists, tuples, mappings, sets, frozensets)

    return st.recursive(base, expand, max_leaves=10)


DATA = recursive_data_strategy()


@given(DATA)
def test_idempotent_and_type_preserved(data):
    """Running prune_data twice without filters should be idempotent and type-stable."""
    r1 = prune_data(data, keys_to_remove=None, values_to_remove=None, remove_empty=False)
    r2 = prune_data(r1, keys_to_remove=None, values_to_remove=None, remove_empty=False)
    assert type(r1) is type(r2)
    assert r1 == r2


@given(DATA)
def test_no_mutation_of_input(data):
    """Input object must not be mutated by prune_data."""
    before = deepcopy(data)
    _ = prune_data(
        data,
        keys_to_remove=lambda k: isinstance(k, str) and k.startswith("secret_"),
        values_to_remove=lambda v: v == "",
        remove_empty=False,
    )
    assert data == before


@given(DATA)
def test_idempotent_with_filters(data):
    """With fixed filters, repeated application should not change the result further."""

    def key_pred(k: object) -> bool:
        return isinstance(k, str) and k == "x"

    def val_pred(v: object) -> bool:
        return v == ""

    r1 = prune_data(data, keys_to_remove=key_pred, values_to_remove=val_pred, remove_empty=True)
    r2 = prune_data(r1, keys_to_remove=key_pred, values_to_remove=val_pred, remove_empty=True)
    assert r1 == r2


@given(DATA)
def test_noop_when_no_filters_and_no_remove_empty(data):
    """If no filters are provided and remove_empty=False, the function returns input as-is."""
    r = prune_data(data, keys_to_remove=None, values_to_remove=None, remove_empty=False)
    assert r is data


def _is_empty(x: object) -> bool:
    if x is None:
        return True
    if isinstance(x, str):
        return x == ""
    if isinstance(x, Mapping):
        return len(x) == 0
    if isinstance(x, AbcSet):
        return len(x) == 0
    if isinstance(x, Sequence) and not isinstance(x, str | bytes | bytearray):
        return len(x) == 0
    return False


def _walk(x: object):
    yield x
    if isinstance(x, Mapping):
        for v in x.values():
            yield from _walk(v)
    elif isinstance(x, Sequence) and not isinstance(x, str | bytes | bytearray):
        for v in x:
            yield from _walk(v)
    elif isinstance(x, AbcSet):
        for v in x:
            yield from _walk(v)


@given(DATA)
def test_no_empty_when_remove_empty(data):
    """With remove_empty=True, the result must not contain empty containers/values."""
    r = prune_data(data, keys_to_remove=None, values_to_remove=None, remove_empty=True)
    it = iter(_walk(r))
    next(it, None)  # ignore root emptiness (allowed for primitives/fully-pruned roots)
    assert all(not _is_empty(v) for v in it)


@given(DATA)
def test_monotonic_by_depth(data):
    """Pruning deeper from an already pruned result equals pruning deeper from original."""

    def key_pred(k: object) -> bool:
        return isinstance(k, str) and k == "secret"

    r1 = prune_data(data, keys_to_remove=key_pred, values_to_remove=None, remove_empty=False, max_depth=1)
    r2a = prune_data(data, keys_to_remove=key_pred, values_to_remove=None, remove_empty=False, max_depth=2)
    r2b = prune_data(r1, keys_to_remove=key_pred, values_to_remove=None, remove_empty=False, max_depth=2)
    assert r2a == r2b


@given(DATA)
def test_sets_hashable(data):
    """All set/frozenset elements in the result must be hashable."""
    from collections.abc import Set as AbcSet

    r = prune_data(data, keys_to_remove=None, values_to_remove=None, remove_empty=False)

    def check(x: object) -> None:
        if isinstance(x, AbcSet):
            for e in x:
                hash(e)
        elif isinstance(x, dict):
            for v in x.values():
                check(v)
        elif isinstance(x, list | tuple):
            for v in x:
                check(v)

    check(r)


@given(DATA)
def test_deterministic(data):
    """Same inputs and params must yield identical outputs."""
    r1 = prune_data(data, ["k"], remove_empty=True)
    r2 = prune_data(data, ["k"], remove_empty=True)
    assert r1 == r2


# ============================================================================
# Property-based tests for walk function
# ============================================================================


@given(DATA)
def test_walk_always_returns_object(data):
    """walk should always return an object, regardless of print_output setting."""
    result1 = walk(data, print_output=True)
    result2 = walk(data, print_output=False)
    # Both should return the same collected data
    assert result1 == result2


@given(DATA)
def test_walk_no_mutation_of_input(data):
    """walk should not mutate the input data."""
    before = deepcopy(data)
    _ = walk(data, print_output=False, max_depth=2, max_items_per_container=5)
    assert data == before


@given(DATA)
def test_walk_deterministic(data):
    """Same inputs should yield identical outputs."""
    r1 = walk(data, print_output=False, max_depth=3, sort_keys=True)
    r2 = walk(data, print_output=False, max_depth=3, sort_keys=True)
    assert r1 == r2


@given(DATA, st.integers(min_value=0, max_value=5))
def test_walk_max_depth_consistent(data, max_depth):
    """Collection and printing should respect max_depth consistently."""
    # Both should apply the same depth limits
    collected = walk(data, print_output=False, max_depth=max_depth)

    # Verify depth is respected by checking nested structure
    def check_depth(obj, current_depth=0):
        if current_depth >= max_depth:
            # At max depth, containers should be empty
            if isinstance(obj, Mapping):
                assert obj == {}
            elif isinstance(obj, Sequence) and not isinstance(obj, str | bytes | bytearray):
                assert obj == [] if isinstance(obj, list) else obj == ()
            elif isinstance(obj, AbcSet):
                assert obj == set() if isinstance(obj, set) else obj == frozenset()
        else:
            # Below max depth, can recurse
            if isinstance(obj, Mapping):
                for v in obj.values():
                    check_depth(v, current_depth + 1)
            elif isinstance(obj, Sequence) and not isinstance(obj, str | bytes | bytearray):
                for v in obj:
                    check_depth(v, current_depth + 1)
            elif isinstance(obj, AbcSet):
                for v in obj:
                    check_depth(v, current_depth + 1)

    check_depth(collected)


@given(DATA, st.integers(min_value=1, max_value=10))
def test_walk_max_items_per_container(data, max_items):
    """max_items_per_container should limit sequences and sets but not mappings."""
    result = walk(data, print_output=False, max_items_per_container=max_items)

    def check_limits(obj):
        if isinstance(obj, Mapping):
            # Mappings are not limited by max_items_per_container
            for v in obj.values():
                check_limits(v)
        elif isinstance(obj, Sequence) and not isinstance(obj, str | bytes | bytearray):
            # Sequences should be limited
            assert len(obj) <= max_items
            for v in obj:
                check_limits(v)
        elif isinstance(obj, AbcSet):
            # Sets should be limited
            assert len(obj) <= max_items
            for v in obj:
                check_limits(v)

    check_limits(result)


@given(DATA)
def test_walk_container_types_preserved(data):
    """Container types should be preserved during collection."""
    result = walk(data, print_output=False)

    def check_types(original, collected):
        if type(original) is not type(collected):
            # Only allow empty containers at depth limits
            if isinstance(original, Mapping) and collected == {}:
                return
            elif isinstance(original, list) and collected == []:
                return
            elif isinstance(original, tuple) and collected == ():
                return
            elif isinstance(original, set) and collected == set():
                return
            elif isinstance(original, frozenset) and collected == frozenset():
                return
            else:
                raise AssertionError(f"Type mismatch: {type(original)} vs {type(collected)}")

        if isinstance(original, Mapping) and isinstance(collected, Mapping):
            for k in collected.keys():
                if k in original:
                    check_types(original[k], collected[k])
        elif isinstance(original, list | tuple) and isinstance(collected, list | tuple):
            for i, v in enumerate(collected):
                if i < len(original):
                    check_types(original[i], v)
        elif isinstance(original, AbcSet) and isinstance(collected, AbcSet):
            # Sets are harder to compare element-wise due to ordering
            pass  # Just check that both are sets of the same type

    check_types(data, result)


# ============================================================================
# Property-based tests for move_unknown_keys_to_extra function
# ============================================================================


# move_unknown_keys_to_extra property-based tests
@given(
    data=st.dictionaries(
        keys=st.one_of(st.text(), st.integers(), st.tuples(st.integers(), st.integers())),
        values=st.one_of(st.text(), st.integers(), st.booleans(), st.none()),
        min_size=0,
        max_size=20,
    ),
    allowed_ratio=st.floats(min_value=0.0, max_value=1.0),
)
def test_move_unknown_keys_property_based(data, allowed_ratio):
    """Property-based test for move_unknown_keys_to_extra with random data."""
    if not data:
        # Empty dict case
        result, moved = move_unknown_keys_to_extra(data, [])
        assert result == {}
        assert moved == []
        return

    # Select random subset of keys as allowed
    all_keys = list(data.keys())
    num_allowed = int(len(all_keys) * allowed_ratio)
    allowed_keys = all_keys[:num_allowed]

    result, moved = move_unknown_keys_to_extra(data, allowed_keys)

    # Property 1: Result should be a dict
    assert isinstance(result, dict)
    assert isinstance(moved, list)

    # Property 2: All allowed keys should be in result with correct values
    for key in allowed_keys:
        str_key = str(key)
        # Key might have collision suffix, but original value should be preserved somewhere
        found = False
        for result_key, result_value in result.items():
            if result_key == str_key or (result_key.startswith(str_key + "__") and str_key != result_key):
                if result_value == data[key]:
                    found = True
                    break
            elif result_key == "extra_collected" and isinstance(result_value, dict):
                for extra_key, extra_value in result_value.items():
                    if extra_key == str_key or (extra_key.startswith(str_key + "__") and str_key != extra_key):
                        if extra_value == data[key]:
                            found = True
                            break
        assert found, f"Key {key} with value {data[key]} not found in result"

    # Property 3: All original values should be preserved somewhere
    original_values = set(data.values())
    result_values = set()

    for value in result.values():
        if isinstance(value, dict):  # extra_collected
            result_values.update(value.values())
        else:
            result_values.add(value)

    # All original values should be preserved (accounting for duplicates)
    for original_value in original_values:
        assert original_value in result_values

    # Property 4: Keys should be sorted
    if "extra_collected" in result:
        extra_keys = list(result["extra_collected"].keys())
        assert extra_keys == sorted(extra_keys)

    top_keys = list(result.keys())
    assert top_keys == sorted(top_keys)

    # Property 5: Moved keys should be sorted
    assert moved == sorted(moved)


@given(
    data=st.dictionaries(
        keys=st.text(min_size=1, max_size=10),
        values=st.text(),
        min_size=1,
        max_size=10,
    )
)
def test_move_unknown_keys_deterministic(data):
    """Property: Multiple runs should produce identical results."""
    allowed_keys = list(data.keys())[: len(data) // 2]  # Take first half

    results = []
    for _ in range(3):
        result, moved = move_unknown_keys_to_extra(data, allowed_keys)
        results.append((result, moved))

    # All results should be identical
    first_result = results[0]
    for result in results[1:]:
        assert result == first_result


@given(
    num_keys=st.integers(min_value=1, max_value=50),
    allowed_ratio=st.floats(min_value=0.0, max_value=1.0),
)
def test_move_unknown_keys_scalability(num_keys, allowed_ratio):
    """Property: Function should handle various data sizes efficiently."""
    # Generate data with known structure
    data = {f"key_{i}": f"value_{i}" for i in range(num_keys)}
    num_allowed = int(num_keys * allowed_ratio)
    allowed_keys = [f"key_{i}" for i in range(num_allowed)]

    result, moved = move_unknown_keys_to_extra(data, allowed_keys)

    # Verify correct partitioning
    expected_kept = num_allowed + (1 if num_keys > num_allowed else 0)  # +1 for extra_collected
    expected_moved = num_keys - num_allowed

    assert len(result) == expected_kept
    assert len(moved) == expected_moved

    if moved:
        assert "extra_collected" in result
        assert len(result["extra_collected"]) == expected_moved


# ============================================================================
# Property-based tests for convert_dict_types function
# ============================================================================


# Strategies for conversion testing
convertible_values = st.one_of(
    st.integers(min_value=-1000, max_value=1000),
    st.floats(min_value=-1000.0, max_value=1000.0, allow_nan=False, allow_infinity=False),
    st.booleans(),
    st.text(min_size=0, max_size=20),
    st.none(),
)

conversion_types = st.sampled_from(["int", "float", "bool", "str", "timestamp_to_iso"])

schema_strategy = st.dictionaries(
    keys=st.text(min_size=1, max_size=10), values=conversion_types, min_size=1, max_size=5
)


@given(
    data=st.dictionaries(keys=st.text(min_size=1, max_size=10), values=convertible_values, min_size=1, max_size=10),
    schema=schema_strategy,
    recursive=st.booleans(),
    strict=st.booleans(),
    empty_string_to_none=st.booleans(),
)
def test_convert_dict_types_property_basic_invariants(data, schema, recursive, strict, empty_string_to_none):
    """Property test: basic invariants should hold for any valid input."""
    try:
        result = convert_dict_types(
            data, schema, recursive=recursive, strict=strict, empty_string_to_none=empty_string_to_none
        )

        # Basic invariants
        assert isinstance(result, dict)
        assert len(result) == len(data)  # Same number of keys

        # All original keys should be present
        assert set(result.keys()) == set(data.keys())

        # Keys not in schema should remain unchanged (unless recursive affects them)
        for key in data:
            if key not in schema:
                if not recursive or not isinstance(data[key], dict | list):
                    assert result[key] == data[key]

    except (ValueError, TypeError, OverflowError):
        # In strict mode, conversion errors are expected for some inputs
        if not strict:
            # In non-strict mode, function should not raise for basic type errors
            # (though it might for other reasons like overflow)
            pass


@given(
    base_data=st.dictionaries(
        keys=st.text(min_size=1, max_size=5), values=st.text(min_size=1, max_size=20), min_size=1, max_size=5
    )
)
def test_convert_dict_types_property_string_to_int_consistency(base_data):
    """Property test: string->int conversion should be consistent."""
    # Filter to only numeric strings that should convert cleanly
    numeric_data = {}
    for key, value in base_data.items():
        if value.isdigit() or (value.startswith("-") and value[1:].isdigit()):
            try:
                int(value)  # Verify it's actually convertible
                numeric_data[key] = value
            except ValueError:
                continue

    if not numeric_data:
        return  # Skip if no valid numeric data

    schema = dict.fromkeys(numeric_data.keys(), "int")

    result = convert_dict_types(numeric_data, schema, strict=False)

    # All values should be successfully converted to int
    for key, original_value in numeric_data.items():
        assert isinstance(result[key], int)
        assert result[key] == int(original_value)


@given(
    nested_data=st.recursive(
        st.dictionaries(
            keys=st.text(min_size=1, max_size=5),
            values=st.one_of(st.text(min_size=1, max_size=10), st.integers()),
            min_size=1,
            max_size=3,
        ),
        lambda children: st.dictionaries(
            keys=st.text(min_size=1, max_size=5),
            values=st.one_of(st.text(min_size=1, max_size=10), children),
            min_size=1,
            max_size=3,
        ),
        max_leaves=10,
    )
)
def test_convert_dict_types_property_recursive_structure_preserved(nested_data):
    """Property test: recursive conversion preserves structure."""
    if not isinstance(nested_data, dict):
        return

    schema = {"dummy": "str"}  # Schema that won't match anything

    # Non-recursive should preserve nested structure exactly
    result_non_recursive = convert_dict_types(nested_data, schema, recursive=False)
    assert result_non_recursive == nested_data

    # Recursive should preserve structure shape (even if values change)
    result_recursive = convert_dict_types(nested_data, schema, recursive=True)

    def same_structure(a, b):
        if type(a) is not type(b):
            return False
        if isinstance(a, dict):
            return set(a.keys()) == set(b.keys()) and all(same_structure(a[k], b[k]) for k in a.keys())
        elif isinstance(a, list):
            return len(a) == len(b) and all(same_structure(x, y) for x, y in zip(a, b, strict=True))
        else:
            return True  # Leaf values may differ

    assert same_structure(nested_data, result_recursive)


@given(
    data=st.dictionaries(
        keys=st.text(min_size=1, max_size=5),
        values=st.one_of(st.none(), st.text(min_size=0, max_size=10)),
        min_size=1,
        max_size=5,
    ),
    empty_string_to_none=st.booleans(),
)
def test_convert_dict_types_property_none_and_empty_handling(data, empty_string_to_none):
    """Property test: None values and empty strings are handled consistently."""
    schema = dict.fromkeys(data.keys(), "str")

    result = convert_dict_types(data, schema, empty_string_to_none=empty_string_to_none)

    for key, value in data.items():
        if value is None:
            # None should always be preserved
            assert result[key] is None
        elif value == "" and empty_string_to_none:
            # Empty string should become None when flag is set
            assert result[key] is None
        elif value == "" and not empty_string_to_none:
            # Empty string should be preserved when flag is not set
            assert result[key] == ""
